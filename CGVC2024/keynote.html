---
layout: default
year: CGVC2024
title: Keynote
---

<h1> {{page.title}} </h1>

<p>Confirmed keynote speakers are:</p>
<ol>
  <li>Bringing Data to Life: Embedded Visualizations for Pervasive and Mobile Data Exploration<br><i><a href="https://lnkd.in/e3tWpU3F">Petra Isenberg</a>, Research Director of INRIA, part of the AVIZ research group and affiliated with the University of Paris-Saclay</i>
  <li>Digital avatars and agents in Virtual Worlds<br><i><a href="https://www.scss.tcd.ie/Rachel.McDonnell/">Rachel McDonnell</a>, Associate Professor in Creative Technologies, School of Computer Science and Statistics, Trinity College Dublin</i>
  <li>Amir Hussain, CEO of <a href="https://www.yemetech.com/home">Yemetech</a>
</ol>

<h2>1. <b>Petra Isenberg:</b> Bringing Data to Life: Embedded Visualizations for Pervasive and Mobile Data Exploration</h2>

<p><img src="documents/petra1.png" height="150px" /><img src="documents/petra2.png" height="150px" /><img src="documents/petra3.png" height="150px" /></p>

<h3>Abstract</h3>
<p>Do you own a smartwatch, watch sports on TV, or play video games? If so, chances are high that you have encountered situated visualizations. In a situated data visualization, the data is directly visualized near the physical space, object, or person it refers to. They are used due to their many potential benefits: they can surface information in the physical environment and allow viewers to interpret data in-context, monitor changes, observe patterns over time, and collaborate with other people.</p>

<p></p>In this presentation I will highlight challenges related to making data available in the form of situated and embedded visualizations. I will show how situating visualizations in the context of mobile devices and embedding them in sports videos and video games poses challenges to the design of interactive visualizations: visualizations need not only to be small and glanceable but also often to be read in motion. I will end with an overview of research on situated visualization more broadly and outline open research opportunities.</p>


<h3>Biography</h3>

<p><a href="https://lnkd.in/e3tWpU3F">Petra Isenberg</a> is a research director(DR) at the Inria Saclay Centre at Université Paris-Saclay, France in the Aviz team and part of the Computer Science Laboratory (LISN) of the University Paris-Saclay. Prior to joining Inria, she received her PhD from the University of Calgary in 2010 on collaborative information visualization. Petra also holds a Diplom-engineer degree in Computational Visualistics from the University of Magdeburg. Her main research areas are visualization and visual analytics with a focus on visualization for non-desktop devices, interaction, and evaluation. She is particularly interested in exploring how people can most effectively work together when analyzing large and complex data sets on novel display technology such as wearables, wall displays, or tabletops. Petra is associate editor-in-chief at IEEE CG&A, associate editor at Computer Graphics Forum, ethics and diversity chair at VGTC, the co-chair of the IEEE VIS Steering Committee, and a member of the IEEE Visualization Academy.</p>



<h2>2. <b>Rachel McDonnell:</b> Digital avatars and agents in Virtual Worlds</h2>

<h3>Abstract</h3>
Recent developments in digital human technologies enable communication with even highly realistic characters in immersive virtual environments. These digital avatars require the human’s motion data to be tracked using tracking systems such as VR headsets and controllers. Research going back to the 1970s has shown that this biological motion data that we are tracking is rich in psychological information such as social categories, emotional state, intentions, and underlying dispositions. In this talk, I will discuss research that I have conducted over the years on the perception of digital humans, with a focus on how congruent and incongruent motion and morphologies are perceived. I will also discuss the implications for avatar-based interactions and virtual agents in the ‘Metaverse’, as technology develops, and motion capture data becomes more accessible to all.

<h3>Biography</h3>
<a href="https://www.scss.tcd.ie/Rachel.McDonnell/">Rachel McDonnell</a> is an Associate Professor in Creative Technologies at the School of Computer Science and Statistics at Trinity College Dublin. She is also a Fellow of Trinity College, a Principal Investigator in the ADAPT Research Centre, and a member of the Graphics, Vision, and Visualisation Group.



